{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python3\n",
    "from Network import get_default_model\n",
    "from keras import optimizers\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.models import Model, load_model\n",
    "import keras.backend as K\n",
    "from DatasetManager import SignalSequence, DataDirectoryReader\n",
    "import datetime\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from Levenshtein import distance, editops\n",
    "from Data import Dataset, ExampleSequence, TrainingExample\n",
    "import sys\n",
    "\n",
    "\n",
    "def write_file_dict_to_file(path, file_dict):\n",
    "    lines = []\n",
    "    for k in file_dict.keys():\n",
    "        lines += [os.path.join(k, x) for x in file_dict[k]]\n",
    "    write_lines_to_file(path, lines)\n",
    "\n",
    "def write_lines_to_file(path, lines):\n",
    "    with open(path, 'w') as file:\n",
    "        for line in lines:\n",
    "            file.write(\"%s\\n\" % line)\n",
    "\n",
    "def write_dict_to_file(path, params):\n",
    "    with open(path, 'w') as file:\n",
    "        json.dump(params, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/home/lubonp/praca_magisterska/Dane/dataset_chiron.dat'\n",
    "model_path = '/home/lubonp/praca_magisterska/Basecaller/basecaller/runs/2019-05-10 15:35:44.651746'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/lubonp/miniconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/lubonp/miniconda3/envs/tf_gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4249: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/lubonp/miniconda3/envs/tf_gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4229: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/lubonp/miniconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(dataset_path)\n",
    "with open(os.path.join(model_path, 'test.txt')) as test_file:\n",
    "    test = [x.strip() for x in test_file.readlines()]\n",
    "test_seq = ExampleSequence(dataset, test, name='test')\n",
    "model = load_model(os.path.join(model_path, 'model.h5'), custom_objects={'<lambda>': lambda y_true, y_pred: y_pred})\n",
    "model = multi_gpu_model(model, gpus=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png')\n",
    "sub_model = model.get_layer('model_2')\n",
    "plot_model(sub_model, to_file='sub_model.png')\n",
    "sub_sub_model = sub_model.get_layer('model_1')\n",
    "plot_model(sub_sub_model, to_file='sub_sub_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/lubonp/miniconda3/envs/tf_gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4303: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n"
     ]
    }
   ],
   "source": [
    "sub_model = model.get_layer('model_2')\n",
    "sub_model = sub_model.get_layer('model_1')\n",
    "im_model = Model(inputs=sub_model.get_input_at(0), outputs =sub_model.get_layer('activation_1').output)\n",
    "dists = []\n",
    "ops = []\n",
    "lens = []\n",
    "pred_lens = []\n",
    "real = []\n",
    "predicted = []\n",
    "for j in range(len(test_seq)):\n",
    "    batch = test_seq[j][0]\n",
    "    preds = im_model.predict_on_batch(batch)\n",
    "    val = K.ctc_decode(preds, np.full(150, batch['input_length'][0,0]), greedy=False)\n",
    "    decoded = K.eval(val[0][0])\n",
    "    for i in range(decoded.shape[0]):\n",
    "        real_label = batch['the_labels'][i, :batch['label_length'][i,0]]\n",
    "        real_label = ''.join([str(int(x)) for x in real_label.tolist()])\n",
    "        pred_label = list(filter(lambda x: x!= -1, decoded[i,:].tolist()))\n",
    "        pred_label = [str(x) for x in pred_label]\n",
    "        pred_label = ''.join(pred_label)\n",
    "        dists.append(distance(pred_label, real_label))\n",
    "        ops.append(editops(pred_label, real_label))\n",
    "        lens.append(len(real_label))\n",
    "        pred_lens.append(len(pred_label))\n",
    "        real.append(real_label)\n",
    "        predicted.append(pred_label)\n",
    "op_counts = {'insert':0, 'replace':0, 'delete':0}\n",
    "for op in ops:\n",
    "    for x in op:\n",
    "        op_counts[x[0]] += 1\n",
    "for key in op_counts.keys():\n",
    "    op_counts[key] = op_counts[key] / sum(lens)\n",
    "metrics = {\n",
    "    'LER': sum(dists)/sum(lens),\n",
    "    'real_mean_length': np.mean(lens),\n",
    "    'predicted_mean_length': np.mean(pred_lens)\n",
    "}\n",
    "metrics.update(op_counts)\n",
    "metrics_file_path = os.path.join(model_path, 'metrics1.json')\n",
    "write_dict_to_file(metrics_file_path, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
